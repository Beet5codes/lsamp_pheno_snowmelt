---
title: "pheno"
author: "rachel torres"
date: "2025-01-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#install.packages("devtools")
#if(!require(remotes)){install.packages("remotes")}
#remotes::install_github("bluegreen-labs/phenor@v1.3.1")
#install.packages("phenocamr")
#install.packages("maps")

library(phenor)
library(phenocamr)
library(maps)
library(raster)
library(tidyverse)
```

## tutorial - NEON pheno packages 

https://www.neonscience.org/resources/learning-hub/tutorials/phenocam-phenor-modeling

For the latest version, install `phenor` from here: https://github.com/bluegreen-labs/phenor (be sure to update all packages for installation to work, and install GenSA)


```{r download}

# example from website: Bartlett NH 
# phenocamr::download_phenocam(
#   frequency = 3,
#   veg_type = "DB", #DB for decid broadlead, EN for evergreen, default is ALL 
#   roi_id = 1000,
#   site = "bartlettir",
#   phenophase = TRUE,
#   out_dir = "." # saves in current working dir
#   )

# evergreens in del norte county (close to north humboldt)
# phenocamr::download_phenocam(
#   frequency = 3,
#   veg_type = "EN", #DB for decid broadlead, EN for evergreen, default is ALL 
#   roi_id = 1000,
#   site = "delnortecounty1",
#   phenophase = TRUE,
#   out_dir = "." # saves in current working dir
#   )

# shrubs in crownpoint NM, NE of Gallup at Navajo Technical University 
#phenocamr::download_phenocam(
#  frequency = 3,
#  roi_id = 1000,
#  site = "ntupinyongarden",
#  phenophase = TRUE,
#  out_dir = "." # saves in current working dir
#  )

# two files: time series and transition data 

# time series - 3 days 
dnc <- read_csv("delnortecounty1_EN_1000_3day.csv", skip = 24)
ntu <- read_csv("ntupinyongarden_SH_1000_3day.csv", skip=24)

# transition data - estimate phenophases for spring and autumn, or when the change in rising or falling Gcc happens 
dnc_t <- read_csv("delnortecounty1_EN_1000_3day_transition_dates.csv", skip=16)

ntu_t <- read_csv("ntupinyongarden_SH_1000_3day_transition_dates.csv", skip=16) # nothing is in this one 

```
# explore data

Find the metadata here:
https://phenocam.nau.edu/webcam/tools/summary_file_format/

```{r explore}
summary(dnc)

names(dnc)

mean(dnc$gcc_90, na.rm=T)
mean(ntu$gcc_90, na.rm=T)

```

# make a plot 

```{r plots}

# evergreens
ggplot(dnc, aes(x=date, y=gcc_90)) + 
  geom_point() +
  geom_smooth()

ggplot(dnc, aes(x=date, y=smooth_gcc_90)) +
  geom_line() 

dnc %>% dplyr::filter(year<2025) %>% 
  ggplot(aes(x=doy, y=smooth_gcc_90, col=as.factor(year))) + 
  geom_line()

# shrubs 
ggplot(ntu, aes(x=date, y=smooth_gcc_90)) +
  geom_line() 
# only available for year 2019 and error after like august 

dnc %>% dplyr::filter(year==2019) %>% 
ggplot() +
  geom_line(aes(x=date, y=smooth_gcc_90, col="Del Norte")) + 
  geom_line(data=ntu, aes(x=date, y=smooth_gcc_90, col="NTU")) 
# years do not overlap

dnc %>% group_by(doy) %>%
  summarize(gcc90 = mean(smooth_gcc_90)) %>% 
ggplot() +
  geom_line(aes(x=doy, y=gcc90, col="Del Norte")) + 
  geom_line(data=ntu, aes(x=doy, y=smooth_gcc_90, col="NTU")) 

# need to find another location for Gallup 

```

## transition days 

```{r transition}
td <- dnc_t %>% 
  dplyr::filter(direction=="rising")

# create a simple line graph of the smooth Green Chromatic Coordinate (Gcc)
# and add points for transition dates
ggplot(dnc, aes(x=as.Date(date), y=smooth_gcc_90)) + 
  geom_line() + 
  geom_point(data=td, aes(x=as.Date(transition_25),
                          y=threshold_25),
             col="red")

# transition date is only available for the year 2023? Plotting when 25% of greenness amplitude (of 90th percentile) is reached 
dnc %>% dplyr::filter(year==2023) %>% 
ggplot(aes(x=as.Date(date), y=smooth_gcc_90)) + 
  geom_line() + 
  geom_point(data=td, aes(x=as.Date(transition_25),
                          y=threshold_25),
             col="red")



```

# climate data: CMIP5 

Using the example from the website, New Hampshire Deciduous Broadleaf, to see how it goes 

```{r nh}
bnh <- read_csv("bartlettir_DB_1000_3day.csv", skip = 24)

bnh_t <- read_csv("bartlettir_DB_1000_3day_transition_dates.csv", skip = 16)

# download source cmip5 data into your temporary directory
# please note this is a large download: >4GB! 
#phenor::download_cmip5(
#  year = 2090,
#  path = tempdir(),
#  model = "MIROC5",
#  scenario = "rcp85"
#  )
# note this is an old function, not available anymore 

```

## use vignette 

https://bluegreen-labs.github.io/phenocamr/articles/phenocamr-vignette.html

source has clear steps, but uses base plotting 

```{r phenocamr}
# read as phenocamr type 
df = read_phenocam("bartlettir_DB_1000_3day.csv")

df <- expand_phenocam(df) # expand every 3 day to every day 

df <- detect_outliers(df) # detect outliers

df <- smooth_ts(df) # smooth data using AIC 

phenology_dates <- phenophases(df, internal = TRUE) # calculate rising and falling

as.data.frame(df$data) %>% 
  mutate(date = as.Date(date)) %>% 
  ggplot(aes(x=date, y=smooth_gcc_90)) + 
  geom_line() +
  labs(x="Date", y="GCC") + 
  # rising "spring" greenup dates 
  geom_vline(data=phenology_dates$rising, aes(xintercept=transition_50), col="green") + 
  # falling 'autumn' senescence dates 
  geom_vline(data=phenology_dates$falling, aes(xintercept=transition_50), col="brown")


```

## climate data: Daymet  

Use the function `merge_daymet`

Daymet is continuous, gridded estimates of weather and climate variables creted through statistical interpolation of ground based measurements. Read more here: https://daymet.ornl.gov/

```{r daymet}

bnh_clim = merge_daymet("bartlettir_DB_1000_3day.csv")

names(bnh_clim)

bnh_data = bnh_clim$data

# plot daily rainfall and temperatures 
ggplot(bnh_data, aes(x=date, y=prcp..mm.day.))+
  geom_line() + 
  labs(y="precip [mm]", title="Daily Precipitation") +
  theme_bw() 

ggplot(bnh_data) +
  geom_point(aes(x=date, y=tmax..deg.c., col="tmax"), col="red") +
  geom_point(aes(x=date, y=tmin..deg.c., col="tmin"), col="blue") +
  labs(y="temp. deg C", title = "Daily temperature") +
  theme_bw()

```

## Explore data with climate 

```{r explore_clim}

# day of the year patterns 
ggplot(bnh_data) +
  geom_point(aes(x=doy, y=gcc_90))

# precipitation
ggplot(bnh_data) + 
  geom_point(aes(x=prcp..mm.day., y=gcc_90, col=doy)) + scale_color_viridis_c()

# day of the year with daylength 
ggplot(bnh_data) + 
   geom_point(aes(x=doy, y=gcc_90, col=dayl..s.)) + scale_color_viridis_c()

# daylength 
ggplot(bnh_data) +
  geom_point(aes(x=doy, y=gcc_90, col=dayl..s.)) + scale_color_viridis_c()

# min temperatures 
ggplot(bnh_data) +
  geom_point(aes(x=tmin..deg.c., y=gcc_90))
# max temperatures 
ggplot(bnh_data) +
  geom_point(aes(x=tmax..deg.c., y=gcc_90))

```

## start with linear model 
```{r lm}

# subset data 
data_mod = bnh_data %>% dplyr::filter(year<2014)

# start with one variable 
lm_test = lm(data=data_mod, gcc_90~dayl..s.)
# see residuals, p-vals, Rsquares, etc. 
summary(lm_test)

# check with more variables 
lm_test2 = lm(data=data_mod, gcc_90~dayl..s.+tmin..deg.c.)

# predict with remaining years
data_pred = bnh_data %>% 
  dplyr::filter(year>=2014) %>% 
  select(gcc_90, dayl..s., tmin..deg.c., year, doy, date) 

# predict with one var
data_pred$pred1_gcc_90 = predict.lm(lm_test, data_pred)

# predict with 2 vars 
data_pred$pred2_gcc_90 = predict.lm(lm_test2, data_pred)

ggplot(data_pred) + 
  geom_point(aes(x=date, y=pred1_gcc_90, col="1 var")) + 
  geom_point(aes(x=date, y=pred2_gcc_90, col="2 vars"))+ 
  geom_point(aes(x=date, y=gcc_90, col="obs")) 

```

## use models from phenoR package 

```{r pars}

# read in parameter ranges 
path <- sprintf("%s/extdata/parameter_ranges.csv",path.package("phenor"))
par_ranges <- read.table(path,
                        header = TRUE,
                        sep = ",")

lin_par = par_ranges %>%
  dplyr::filter(model=="LIN") %>% 
  select(a,b)

# load data from phenor package
bnh = phenocam_DB$bartlettir # in proper format for models 

# data must be formated for input 
tmp = LIN(par=c(a=1000, b=1000), data=bnh)

```